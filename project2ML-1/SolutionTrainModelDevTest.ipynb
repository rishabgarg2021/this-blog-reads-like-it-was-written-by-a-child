{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "col_Names =[\"userID\", \"gender\", \"age\", \"occupation\", \"starSign\", \"date\", \"text\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train_raw.csv succesfully\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_raw.csv', names=col_Names)\n",
    "print(\"read train_raw.csv succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read t_raw.csv succesfully\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('dev_raw.csv',names=col_Names)\n",
    "print(\"read t_raw.csv succesfully\")\n",
    "df_test = (df_test.groupby(['userID','age'])['text'].apply(' '.join).reset_index())\n",
    "df_test.loc[~df_test.age.isin([14,15,16,24,25,26,34,35,36,44,45,46]),'age'] = 0\n",
    "df_test.loc[df_test.age.isin([14,15,16]),'age'] = 1\n",
    "df_test.loc[df_test.age.isin([24,25,26]),'age'] = 2\n",
    "df_test.loc[df_test.age.isin([34,35,36]),'age'] = 3\n",
    "df_test.loc[df_test.age.isin([44,45,46]),'age'] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty space and start spaces from normalise train dataFrame\n",
    "indices_to_remove=[]\n",
    "index=0\n",
    "for row in df_train.itertuples():\n",
    "    text = str(row.text.strip())\n",
    "    df_train.at[row[0],'text']=text\n",
    "    if len(text)==0:\n",
    "        indices_to_remove.append(index)\n",
    "    index+=1\n",
    "df_train=df_train.drop(df_train.index[indices_to_remove])\n",
    "df_train=df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.groupby(['userID','age'])['text'].apply(' '.join).reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.age.isin([14,15,16]),'age'] = 1\n",
    "df_train.loc[df_train.age.isin([24,25,26]),'age'] = 2\n",
    "df_train.loc[df_train.age.isin([34,35,36]),'age'] = 3\n",
    "df_train.loc[df_train.age.isin([44,45,46]),'age'] = 4\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dev_raw.csv succesfully\n"
     ]
    }
   ],
   "source": [
    "df_test_check = pd.read_csv('dev_raw.csv',names=col_Names)\n",
    "print(\"read dev_raw.csv succesfully\")\n",
    "df_test_check.loc[df_test_check.age.isin([14,15,16]),'age'] = 1\n",
    "df_test_check.loc[df_test_check.age.isin([24,25,26]),'age'] = 2\n",
    "df_test_check.loc[df_test_check.age.isin([34,35,36]),'age'] = 3\n",
    "df_test_check.loc[df_test_check.age.isin([44,45,46]),'age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive baeyes is  0.5914144533662755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.72      0.80      0.76     13100\n",
      "      24-26       0.53      0.94      0.68     17298\n",
      "      34-36       0.06      0.01      0.01      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.42      0.59      0.48     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive baeyes is  0.5818185828994971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.70      0.81      0.75     13100\n",
      "      24-26       0.52      0.89      0.66     17298\n",
      "      34-36       0.37      0.10      0.16      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.42      0.58      0.48     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive baeyes is  0.5738551133856878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.70      0.83      0.76     13100\n",
      "      24-26       0.52      0.86      0.65     17298\n",
      "      34-36       0.21      0.10      0.14      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.41      0.57      0.48     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive baeyes is  0.581972999205859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.70      0.83      0.76     13100\n",
      "      24-26       0.52      0.90      0.66     17298\n",
      "      34-36       0.19      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.41      0.58      0.47     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive baeyes is  0.5818185828994971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.69      0.82      0.75     13100\n",
      "      24-26       0.52      0.90      0.66     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.40      0.58      0.47     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "y=df_train['age']\n",
    "smooth=[0.000001,0.0001,0.001,0.01,1]\n",
    "for a in smooth:\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('clf', MultinomialNB(alpha=a)),])\n",
    "    text_clf = text_clf.fit(df_train['text'], y)\n",
    "    predicted = text_clf.predict(df_test['text'])\n",
    "    userID_list=list(df_test['userID'])\n",
    "    \n",
    "    from collections import defaultdict\n",
    "\n",
    "    dict_predict=defaultdict(int)\n",
    "    for i in range(0,len(predicted)):\n",
    "        dict_predict[userID_list[i]]=predicted[i]\n",
    "\n",
    "    correct_result=[]\n",
    "    for row in df_test_check.itertuples():\n",
    "        correct_result.append((df_test_check.at[row[0],'userID'],df_test_check.at[row[0],'age']))\n",
    "    predict=0\n",
    "    total = -1\n",
    "    not_p = -1\n",
    "    for i in range(0,len(correct_result)):\n",
    "        total+=1\n",
    "        userID_to_check=correct_result[i][0]\n",
    "        if dict_predict[userID_to_check] == correct_result[i][1]:\n",
    "            predict+=1\n",
    "        else:\n",
    "            not_p+=1\n",
    "\n",
    "    print(\"accuracy for naive baeyes is \",predict/len(correct_result))\n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "    report_nb=classification_report(df_test['age'],predicted,target_names=target_names)\n",
    "    y_p_nb=[]\n",
    "    for i in range(0,len(correct_result)):\n",
    "        y_p_nb.append(dict_predict[correct_result[i][0]] )\n",
    "    y_t_nb=[x[1] for x in correct_result]\n",
    "    target_names=[\"14-16\",\"24-26\",\"34-36\",\"44-46\"]\n",
    "    report_nb=classification_report(y_t_nb,y_p_nb,target_names=target_names)\n",
    "    print(report_nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_p_nb=[]\n",
    "for i in range(0,len(correct_result)):\n",
    "    y_p_nb.append(dict_predict[correct_result[i][0]] )\n",
    "y_t_nb=[x[1] for x in correct_result]\n",
    "target_names=[\"14-16\",\"24-26\",\"34-36\",\"44-46\"]\n",
    "report_nb=classification_report(y_t_nb,y_p_nb,target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_nb=[]\n",
    "for i in range(0,len(correct_result)):\n",
    "    (correct_result[i][0],dict_predict[correct_result[i][0]])\n",
    "    if dict_predict[correct_result[i][0]] ==1:\n",
    "        new_pred_nb.append((correct_result[i][0],\"14-16\"))\n",
    "    if dict_predict[correct_result[i][0]] ==2:\n",
    "        new_pred_nb.append((correct_result[i][0],\"24-26\"))\n",
    "    if dict_predict[correct_result[i][0]]==3:\n",
    "        new_pred_nb.append((correct_result[i][0],\"34-36\"))\n",
    "    if dict_predict[correct_result[i][0]] ==4:\n",
    "        new_pred_nb.append((correct_result[i][0],\"44-46\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  1   0.6096355775169858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.69      0.90      0.78     13100\n",
      "      24-26       0.56      0.91      0.70     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.41      0.61      0.49     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  3   0.6306803141268861\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.72      0.93      0.81     13100\n",
      "      24-26       0.58      0.95      0.72     17298\n",
      "      34-36       0.36      0.01      0.01      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.45      0.63      0.51     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  5   0.6321582987734934\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.70      0.94      0.80     13100\n",
      "      24-26       0.59      0.94      0.73     17298\n",
      "      34-36       0.15      0.01      0.02      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.44      0.63      0.51     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  10   0.6368128474366893\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.71      0.94      0.81     13100\n",
      "      24-26       0.60      0.95      0.73     17298\n",
      "      34-36       0.38      0.05      0.08      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.45      0.64      0.52     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  13   0.6396805788405542\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.71      0.94      0.81     13100\n",
      "      24-26       0.60      0.95      0.73     17298\n",
      "      34-36       0.48      0.07      0.13      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.46      0.64      0.52     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  20   0.6404747198447013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.69      0.95      0.80     13100\n",
      "      24-26       0.61      0.95      0.75     17298\n",
      "      34-36       0.32      0.09      0.13      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.45      0.64      0.52     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression with alpha =  100   0.6354010412070943\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.71      0.95      0.81     13100\n",
      "      24-26       0.63      0.93      0.75     17298\n",
      "      34-36       0.13      0.10      0.11      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.45      0.64      0.53     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "C=[1,3,5,10,13,20,100]\n",
    "# C=[20]\n",
    "\n",
    "y=df_train['age']\n",
    "for al in C:\n",
    "    text_clf_lg = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                                  ('clf-svm',LogisticRegression(C=al)),])\n",
    "\n",
    "    _ = text_clf_lg.fit(df_train['text'], y)\n",
    "    predicted_lg = text_clf_lg.predict(df_test['text'])\n",
    "    userID_list=list(df_test['userID'])\n",
    "\n",
    "\n",
    "    dict_predict=defaultdict(int)\n",
    "    for i in range(0,len(predicted_lg)):\n",
    "        dict_predict[userID_list[i]]=predicted_lg[i]\n",
    "\n",
    "    correct_result=[]\n",
    "    for row in df_test_check.itertuples():\n",
    "        correct_result.append((df_test_check.at[row[0],'userID'],df_test_check.at[row[0],'age']))\n",
    "    predict=0\n",
    "    total = -1\n",
    "    not_p = -1\n",
    "    for i in range(0,len(correct_result)):\n",
    "        total+=1\n",
    "        userID_to_check=correct_result[i][0]\n",
    "        if dict_predict[userID_to_check] == correct_result[i][1]:\n",
    "            predict+=1\n",
    "        else:\n",
    "            not_p+=1\n",
    "    print(\"accuracy for logistic regression with alpha = \",al , \" \", predict/len(correct_result))\n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "    report_lg=classification_report(df_test['age'],predicted_lg,target_names=target_names)\n",
    "    y_p_lg=[]\n",
    "    for i in range(0,len(correct_result)):\n",
    "        y_p_lg.append(dict_predict[correct_result[i][0]] )\n",
    "    y_t_lg=[x[1] for x in correct_result]\n",
    "    target_names=[\"14-16\",\"24-26\",\"34-36\",\"44-46\"]\n",
    "    report_lg=classification_report(y_t_lg,y_p_lg,target_names=target_names)\n",
    "    print(report_lg)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dev_raw.csv succesfully\n"
     ]
    }
   ],
   "source": [
    "#played with confidence of best model of class preiction\n",
    "# proba_lg = text_clf_lg.predict_proba(df_test['text'])\n",
    "# class1_1=[]\n",
    "# class1_not_1=[]\n",
    "# class2_2=[]\n",
    "# class2_not_2=[]\n",
    "# class1_1_2=[]\n",
    "# i=-1\n",
    "# pr=0\n",
    "# ac=0\n",
    "# predicted_lg = text_clf_lg.predict(df_test['text'])\n",
    "# for row in df_test.itertuples():\n",
    "#     i+=1\n",
    "#     if df_test.loc[i]['age'] == predicted_lg[i] == 1:\n",
    "#         class1_1.append(proba_lg[i][0])\n",
    "# #         print(proba_lg[i])\n",
    "# #         print(proba_lg[i][0]-proba_lg[i][1])\n",
    "#         class1_1_2.append(proba_lg[i][0]-proba_lg[i][1])\n",
    "#     if df_test.loc[i]['age'] not in [11,12,13,14,15,16,17,18,19] and predicted_lg[i] ==1:\n",
    "#         class1_not_1.append(proba_lg[i][0])\n",
    "#     if df_test.loc[i]['age'] == predicted_lg[i] == 2:\n",
    "#         class2_2.append(proba_lg[i][1])\n",
    "#     if df_test.loc[i]['age'] not in  [21,22,23,24,25,26,27,28,29] and predicted_lg[i] ==2:\n",
    "#         class2_not_2.append(proba_lg[i][1])\n",
    "    \n",
    "# #     if df_test.loc[i]['age'] in [11,12,13,14,15,16,17,18,19]  and predicted_lg[i] !=1:\n",
    "# #         1==1\n",
    "#     if  proba_lg[i][0] in (0.23,0.24,0.25,0.26,.27,.28) and proba_lg[i][1] in (0.23,0.24,0.25,0.26,.27,.28):\n",
    "#           predicted_lg[i]=0\n",
    "        \n",
    "# i=-1\n",
    "# pr=0\n",
    "# ac=0\n",
    "# for row in df_test.itertuples():\n",
    "#     i+=1\n",
    "#     if abs(proba_lg[i][0]-proba_lg[i][1]) < 0.09  and proba_lg[i][0]<0.5 and proba_lg[i][1]<0.5:\n",
    "#           predicted_lg[i]=0\n",
    "        \n",
    "# #     if /abs(proba_lg[i][0]-proba_lg[i][1]) < 0.03  and proba_lg[i][0]<0.6 and proba_lg[i][1]<0.6:\n",
    "   \n",
    "# print(np.mean(predicted_lg==df_test['age']))\n",
    "\n",
    "# userID_list=list(df_test['userID'])\n",
    "\n",
    "\n",
    "# dict_predict=defaultdict(int)\n",
    "# for i in range(0,len(predicted_lg)):\n",
    "#     dict_predict[userID_list[i]]=predicted_lg[i]\n",
    "\n",
    "# correct_result=[]\n",
    "# for row in df_test_check.itertuples():\n",
    "#     correct_result.append((df_test_check.at[row[0],'userID'],df_test_check.at[row[0],'age']))\n",
    "# predict=0\n",
    "# total = -1\n",
    "# not_p = -1\n",
    "# for i in range(0,len(correct_result)):\n",
    "#     total+=1\n",
    "#     userID_to_check=correct_result[i][0]\n",
    "#     if dict_predict[userID_to_check] == correct_result[i][1]:\n",
    "#         predict+=1\n",
    "#     else:\n",
    "#         not_p+=1\n",
    "\n",
    "# print(predict/len(correct_result))\n",
    "# print()  \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVM classifier is as : 0.62816553428042\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.66      0.94      0.78     13100\n",
      "      24-26       0.61      0.92      0.73     17298\n",
      "      34-36       0.27      0.05      0.08      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.44      0.63      0.51     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVM classifier is as : 0.584068649077914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.67      0.84      0.74     13100\n",
      "      24-26       0.54      0.89      0.67     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.40      0.58      0.47     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVM classifier is as : 0.4154681020030001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.83      0.12      0.21     13100\n",
      "      24-26       0.40      1.00      0.57     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.39      0.42      0.28     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVM classifier is as : 0.41676961087090797\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.82      0.12      0.21     13100\n",
      "      24-26       0.40      1.00      0.57     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.39      0.42      0.28     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "alphas = [1e-5,1e-3,1e-1,1]\n",
    "for a in alphas:\n",
    "    text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                             ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=a, max_iter=5, random_state=42)),])\n",
    "    _ = text_clf_svm.fit(df_train['text'], y)\n",
    "    predicted_svm = text_clf_svm.predict(df_test['text'])\n",
    "    userID_list=list(df_test['userID'])\n",
    "\n",
    "\n",
    "    dict_predict=defaultdict(int)\n",
    "    for i in range(0,len(predicted)):\n",
    "        dict_predict[userID_list[i]]=predicted_svm[i]\n",
    "\n",
    "    correct_result=[]\n",
    "    for row in df_test_check.itertuples():\n",
    "        correct_result.append((df_test_check.at[row[0],'userID'],df_test_check.at[row[0],'age']))\n",
    "    predict=0\n",
    "    total = -1\n",
    "    not_p = -1\n",
    "    for i in range(0,len(correct_result)):\n",
    "        total+=1\n",
    "        userID_to_check=correct_result[i][0]\n",
    "        if dict_predict[userID_to_check] == correct_result[i][1]:\n",
    "            predict+=1\n",
    "        else:\n",
    "            not_p+=1\n",
    "\n",
    "    print(\"accuracy for SVM classifier is as :\",predict/len(correct_result))\n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "    report_svm=classification_report(df_test['age'],predicted_svm,target_names=target_names)\n",
    "    y_p_svm=[]\n",
    "    for i in range(0,len(correct_result)):\n",
    "        y_p_svm.append(dict_predict[correct_result[i][0]] )\n",
    "    y_t_svm=[x[1] for x in correct_result]\n",
    "\n",
    "    target_names=[\"14-16\",\"24-26\",\"34-36\",\"44-46\"]\n",
    "    report_svm=classification_report(y_t_svm,y_p_svm,target_names=target_names)\n",
    "    print(report_svm)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198535251036795\n",
      "45332\n",
      "45332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      14-16       0.51      0.70      0.59     13100\n",
      "      24-26       0.53      0.83      0.64     17298\n",
      "      34-36       0.00      0.00      0.00      2584\n",
      "      44-46       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.35      0.52      0.42     45332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 18, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inlin\n",
    "from sklearn.metrics import accuracy_score\n",
    "#best split at 1700\n",
    "\n",
    "text_clf_tree = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('c',DecisionTreeClassifier(min_samples_split =1700)),])\n",
    "\n",
    "dt = text_clf_tree.fit(df_train['text'], y)\n",
    "predicted_tree = text_clf_tree.predict(df_test['text'])\n",
    "np.mean(predicted_tree == df_test['age'])\n",
    "userID_list=list(df_test['userID'])\n",
    "\n",
    "\n",
    "dict_predict=defaultdict(int)\n",
    "for i in range(0,len(predicted)):\n",
    "    dict_predict[userID_list[i]]=predicted_tree[i]\n",
    "\n",
    "correct_result=[]\n",
    "for row in df_test_check.itertuples():\n",
    "    correct_result.append((df_test_check.at[row[0],'userID'],df_test_check.at[row[0],'age']))\n",
    "predict=0\n",
    "total = -1\n",
    "not_p = -1\n",
    "for i in range(0,len(correct_result)):\n",
    "    total+=1\n",
    "    userID_to_check=correct_result[i][0]\n",
    "    if dict_predict[userID_to_check] == correct_result[i][1]:\n",
    "        predict+=1\n",
    "    else:\n",
    "        not_p+=1\n",
    "\n",
    "print(\"decision tree predicted the accuracy of  \", predict/len(correct_result))\n",
    "\n",
    "new_pred_tree=[]\n",
    "for i in range(0,len(correct_result)):\n",
    "    (correct_result[i][0],dict_predict[correct_result[i][0]])\n",
    "    if dict_predict[correct_result[i][0]] ==1:\n",
    "        new_pred_tree.append((correct_result[i][0],\"14-16\"))\n",
    "    if dict_predict[correct_result[i][0]] ==2:\n",
    "        new_pred_tree.append((correct_result[i][0],\"24-26\"))\n",
    "    if dict_predict[correct_result[i][0]]==3:\n",
    "        new_pred_tree.append((correct_result[i][0],\"34-36\"))\n",
    "    if dict_predict[correct_result[i][0]] ==4:\n",
    "        new_pred_tree.append((correct_result[i][0],\"44-46\"))\n",
    "\n",
    "y_p_tree=[]\n",
    "for i in range(0,len(correct_result)):\n",
    "    y_p_tree.append(dict_predict[correct_result[i][0]] )\n",
    "y_t_tree=[x[1] for x in correct_result]\n",
    "target_names=[\"14-16\",\"24-26\",\"34-36\",\"44-46\"]\n",
    "report_tree=classification_report(y_t_tree,y_p_tree,target_names=target_names)\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
