{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                fre\n",
      "count  33372.000000\n",
      "mean      74.719701\n",
      "std      147.744011\n",
      "min    -9183.788605\n",
      "25%       67.823768\n",
      "50%       79.284815\n",
      "75%       89.016001\n",
      "max      205.372128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection, neighbors\n",
    "import re\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "col_Names =[\"userID\", \"gender\", \"age\", \"occupation\", \"starSign\", \"date\", \"text\", \"len_text\", \n",
    "            \"capitalized_letters\", \"ratio_capital_total\", \"ratio_spaces_total\" , \"ratio_spaces_non_spaces\",\n",
    "            \"ratio_capital_lower_case\" ,\"ratio_numeric_total\", \"special_chars\", \"count_once\", \"count_twice\", \n",
    "            \"avg_len\", \"max_len\", \"words_with_numbers\", \"words_shorter_three_letters\", \"ratio_distinct_words_total\", \n",
    "            \"sum_punctuation\", \"ratio_punctuation_text\", \"hypen_words\", \"avg_sen_len_words\", \n",
    "            \"avg_sen_len_chars\", \"class\"]\n",
    "features = [  \"len_text\",\n",
    "            \"capitalized_letters\", \"ratio_capital_total\", \"ratio_spaces_total\" , \"ratio_spaces_non_spaces\",\n",
    "            \"ratio_capital_lower_case\" ,\"ratio_numeric_total\", \"special_chars\", \"count_once\", \"count_twice\", \n",
    "            \"avg_len\", \"max_len\", \"words_with_numbers\", \"words_shorter_three_letters\", \"ratio_distinct_words_total\", \n",
    "            \"sum_punctuation\", \"ratio_punctuation_text\", \"hypen_words\", \"avg_sen_len_words\", \n",
    "            \"avg_sen_len_chars\",\"fre\"]\n",
    "\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"e\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_csv(csv_file, output_file):\n",
    "    df = pd.read_csv(csv_file, names=col_Names, dtype = str)\n",
    "\n",
    "    count=-1\n",
    "    remove_rows=[]\n",
    "    for row in df.itertuples():\n",
    "        count+=1\n",
    "        if int(row.age) in [n for n in range(14,17)]:\n",
    "            df.at[row[0],'class'] = '14-16'\n",
    "        elif int(row.age) in [n for n in range(24,27)]:\n",
    "            df.at[row[0],'class'] = '24-26'\n",
    "        elif int(row.age) in [n for n in range(34,37)]:\n",
    "            df.at[row[0],'class'] = '34-36'\n",
    "        elif int(row.age) in [n for n in range(44,47)]:\n",
    "            df.at[row[0],'class'] = '44-46'\n",
    "            #for testing file we can;t remove because it will decrease our accuracy as number of instance we check become less/\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            remove_rows.append(count)\n",
    "            continue\n",
    "        text = str(row.text.strip())\n",
    "        sents = text.split('.')\n",
    "        avg_sen_len_words = sum(len(x.split()) for x in sents) / len(sents)\n",
    "        avg_sen_len_chars = sum(len(x) for x in sents) / len(sents)\n",
    "        hypen_words = len(re.findall(r'\\w+(?:-\\w+)+',text))\n",
    "        count_once = 0\n",
    "        count_twice = 0\n",
    "        sum_len = 0\n",
    "        max_len = 0\n",
    "        words_with_numbers = 0\n",
    "        words_shorter_three_letters = 0\n",
    "        len_text = len(text)\n",
    "        if len_text == 0:\n",
    "            df.at[row[0],'text'] = ''\n",
    "            len_text=0\n",
    "        \n",
    "       \n",
    "        capitalized_letters = len(re.findall(r'[A-Z]',text))\n",
    "        lower_case_letters = sum(map(str.islower, text))\n",
    "        if len_text == 0:\n",
    "            remove_rows.append(count)\n",
    "            continue\n",
    "        ratio_capital_total = round(capitalized_letters / len_text,3)\n",
    "        spaces = text.count(' ')\n",
    "        if spaces == len_text:\n",
    "            remove_rows.append(count)\n",
    "            continue\n",
    "\n",
    "        sum_punctuation = sum(Counter(c for c in text if c in punctuation).values())\n",
    "        for key, val in Counter(text.split()).items():\n",
    "            if len(key) < 3:\n",
    "                words_shorter_three_letters += 1\n",
    "            matches = re.findall('[0-9]', key)\n",
    "            if len(matches) > 0:\n",
    "                words_with_numbers += 1\n",
    "            sum_len += len(key)\n",
    "            if len(key) >= max_len:\n",
    "                max_len = len(key)\n",
    "            if val == 1:\n",
    "                count_once +=1\n",
    "            elif val == 2:\n",
    "                count_twice += 1\n",
    "\n",
    "        ratio_spaces_total = round(spaces / len_text,3)\n",
    "        ratio_spaces_non_spaces = round(spaces / (len_text - spaces),3)\n",
    "        if lower_case_letters == 0:\n",
    "            lower_case_letters = 1\n",
    "        ratio_capital_lower_case = round(capitalized_letters / (lower_case_letters),3)\n",
    "        numeric = sum(c.isdigit() for c in text)\n",
    "        ratio_numeric_total = round(numeric / len_text,3)\n",
    "        special_chars = len(text) - spaces - len( re.findall('[\\w]', text) )\n",
    "        ratio_punctuation_text = round(sum_punctuation / len_text, 3)\n",
    "        num_of_words = len(text.split())\n",
    "        avg_len = round(sum_len / num_of_words,3)\n",
    "        ratio_distinct_words_total = round(count_once / num_of_words, 3)\n",
    "        arg1 = 206.835\n",
    "        arg2 = 1.015 * (num_of_words / len(sents))\n",
    "        arg3 = 84.6 * (syllable_count(text) / num_of_words)\n",
    "\n",
    "        fre = arg1 -arg2 -arg3\n",
    "        fre1=fre\n",
    "        \n",
    "        if(fre1>=121.22):\n",
    "            fre1=2\n",
    "        d={1:\"14-16\",2:\"24-26\",3:\"34-36\",4:\"44-46\"}\n",
    "        if 90<=fre1:\n",
    "            fre1 = 1\n",
    "            \n",
    "        elif 30<=fre1<90:\n",
    "            fre1 = 2\n",
    "        elif 10<fre1<30:\n",
    "            fre1=3\n",
    "        else:\n",
    "            fre1=4\n",
    "        \n",
    "        df.at[row[0],'len_text'] = len_text\n",
    "        df.at[row[0],'capitalized_letters'] = capitalized_letters\n",
    "        df.at[row[0],'ratio_capital_total'] = ratio_capital_total*100\n",
    "        df.at[row[0],'ratio_spaces_total'] = ratio_spaces_total*100\n",
    "        df.at[row[0],'ratio_spaces_non_spaces'] = ratio_spaces_non_spaces*100\n",
    "        df.at[row[0],'ratio_capital_lower_case'] = ratio_capital_lower_case*100\n",
    "        df.at[row[0],'ratio_numeric_total'] = ratio_numeric_total*100\n",
    "        df.at[row[0],'special_chars'] = special_chars\n",
    "        df.at[row[0],'count_once'] = count_once\n",
    "        df.at[row[0],'count_twice'] = count_twice\n",
    "        df.at[row[0],'avg_len'] = avg_len\n",
    "        df.at[row[0],'max_len'] = max_len\n",
    "        df.at[row[0],'words_with_numbers'] = words_with_numbers\n",
    "        df.at[row[0],'words_shorter_three_letters'] = words_shorter_three_letters\n",
    "        df.at[row[0],'ratio_distinct_words_total'] = ratio_distinct_words_total*100\n",
    "        df.at[row[0],'sum_punctuation'] = sum_punctuation\n",
    "        df.at[row[0],'ratio_punctuation_text'] = ratio_punctuation_text*100\n",
    "        df.at[row[0],'hypen_words'] = hypen_words\n",
    "        df.at[row[0],'avg_sen_len_words'] = avg_sen_len_words\n",
    "        df.at[row[0],'avg_sen_len_chars'] = avg_sen_len_chars\n",
    "        df.at[row[0],'fre'] = fre\n",
    "    count = 0\n",
    "    col_scores=[]\n",
    " \n",
    "    indexes_to_keep = set(range(df.shape[0]))-set(remove_rows)\n",
    "   \n",
    "    df1=df.take(list(indexes_to_keep))\n",
    "    print(df1.describe())\n",
    "    #last column for age\n",
    "    y= df1['class']\n",
    "    \n",
    "    \n",
    "    for j in col_Names:\n",
    "        if j not in features:\n",
    "            \n",
    "            df1=df1.drop([j],axis=1)\n",
    "   \n",
    "    \n",
    "        \n",
    "    mean_list=list(df1.mean())\n",
    "    max_list = list(df1.max())\n",
    "    min_list=list(df1.min())\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "    for row in df1.itertuples():                  \n",
    "        j=0       \n",
    "        \n",
    "        for col in df1.columns:\n",
    "            df1.at[row[0],col] = (df1.at[row[0],col] - float(mean_list[j])) / (float(max_list[j]) - float(min_list[j]))\n",
    "            j+=1\n",
    "  \n",
    "    df2 = pd.concat([df1,y], axis=1)\n",
    "    df2.to_csv(output_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# write_csv('train_raw.csv', 'final_train_remove_features_fre2.csv')\n",
    "write_csv('dev_raw.csv', \"final_dev_remove_features_fre02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7cfe3631410c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   len_text  capitalized_letters  ratio_capital_total  ratio_spaces_total  \\\n",
      "0 -0.006717            -0.003510            -0.013635            0.015943   \n",
      "1  0.035621             0.009841            -0.008635            0.015943   \n",
      "2 -0.047011            -0.013746            -0.022635            0.004038   \n",
      "3  0.000057            -0.000840            -0.011635            0.022556   \n",
      "4 -0.055304            -0.015526            -0.044635           -0.009190   \n",
      "\n",
      "   ratio_spaces_non_spaces  ratio_capital_lower_case  ratio_numeric_total  \\\n",
      "0                 0.005367                 -0.000233             0.000887   \n",
      "1                 0.005367                 -0.000226            -0.002113   \n",
      "2                 0.000860                 -0.000244            -0.005113   \n",
      "3                 0.007621                 -0.000229            -0.004113   \n",
      "4                -0.003970                 -0.000271            -0.005113   \n",
      "\n",
      "   special_chars  count_once  count_twice    ...      max_len  \\\n",
      "0      -0.004878    0.002637     0.010836    ...    -0.002142   \n",
      "1      -0.001628    0.098422     0.049943    ...    -0.001705   \n",
      "2      -0.007363   -0.119969    -0.072963    ...    -0.001705   \n",
      "3      -0.002966    0.029457     0.033183    ...    -0.002579   \n",
      "4      -0.007745   -0.165946    -0.067376    ...    -0.003454   \n",
      "\n",
      "   words_with_numbers  words_shorter_three_letters  \\\n",
      "0            0.001706                     0.034309   \n",
      "1            0.010326                     0.171295   \n",
      "2           -0.015536                    -0.075280   \n",
      "3           -0.006915                     0.061706   \n",
      "4           -0.015536                    -0.184869   \n",
      "\n",
      "   ratio_distinct_words_total  sum_punctuation  ratio_punctuation_text  \\\n",
      "0                   -0.104748        -0.004813               -0.029369   \n",
      "1                   -0.178748        -0.001563               -0.028369   \n",
      "2                    0.188252        -0.007298               -0.018369   \n",
      "3                   -0.104748        -0.002901               -0.022369   \n",
      "4                    0.105252        -0.007680                0.053631   \n",
      "\n",
      "   hypen_words  avg_sen_len_words  avg_sen_len_chars       fre  \n",
      "0     -0.02892           0.007023           0.002028  0.000694  \n",
      "1     -0.02892           0.002946           0.000731  0.000262  \n",
      "2     -0.02892          -0.005207          -0.002860  0.001084  \n",
      "3     -0.02892          -0.001314          -0.001364  0.002122  \n",
      "4     -0.02892          -0.015855          -0.007234  0.003761  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   len_text  capitalized_letters  ratio_capital_total  ratio_spaces_total  \\\n",
      "0 -0.006717            -0.003510            -0.013635            0.015943   \n",
      "1  0.035621             0.009841            -0.008635            0.015943   \n",
      "2 -0.047011            -0.013746            -0.022635            0.004038   \n",
      "3  0.000057            -0.000840            -0.011635            0.022556   \n",
      "4 -0.055304            -0.015526            -0.044635           -0.009190   \n",
      "\n",
      "   ratio_spaces_non_spaces  ratio_capital_lower_case  special_chars  \\\n",
      "0                 0.005367                 -0.000233      -0.004878   \n",
      "1                 0.005367                 -0.000226      -0.001628   \n",
      "2                 0.000860                 -0.000244      -0.007363   \n",
      "3                 0.007621                 -0.000229      -0.002966   \n",
      "4                -0.003970                 -0.000271      -0.007745   \n",
      "\n",
      "   count_once  count_twice   avg_len   max_len  words_shorter_three_letters  \\\n",
      "0    0.002637     0.010836 -0.001637 -0.002142                     0.034309   \n",
      "1    0.098422     0.049943 -0.001903 -0.001705                     0.171295   \n",
      "2   -0.119969    -0.072963 -0.000432 -0.001705                    -0.075280   \n",
      "3    0.029457     0.033183 -0.001770 -0.002579                     0.061706   \n",
      "4   -0.165946    -0.067376 -0.000614 -0.003454                    -0.184869   \n",
      "\n",
      "   ratio_distinct_words_total  sum_punctuation  ratio_punctuation_text  \\\n",
      "0                   -0.104748        -0.004813               -0.029369   \n",
      "1                   -0.178748        -0.001563               -0.028369   \n",
      "2                    0.188252        -0.007298               -0.018369   \n",
      "3                   -0.104748        -0.002901               -0.022369   \n",
      "4                    0.105252        -0.007680                0.053631   \n",
      "\n",
      "   avg_sen_len_words  avg_sen_len_chars       fre  \n",
      "0           0.007023           0.002028  0.000694  \n",
      "1           0.002946           0.000731  0.000262  \n",
      "2          -0.005207          -0.002860  0.001084  \n",
      "3          -0.001314          -0.001364  0.002122  \n",
      "4          -0.015855          -0.007234  0.003761  \n",
      "[0.05597253 0.05227443 0.05848461 0.05295045 0.0523899  0.05402931\n",
      " 0.05330902 0.05662626 0.04764486 0.05699021 0.05230249 0.05324516\n",
      " 0.05269122 0.05390057 0.06745719 0.05957997 0.06221976 0.05793206]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection, neighbors\n",
    "import re\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load data\n",
    "df = pd.read_csv(\"final_dev_remove_features_fre02.csv\")\n",
    "df1 = pd.read_csv(\"final_dev_remove_features_fre02.csv\")\n",
    "#unnamed column removed from df\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "df1=df1.drop(df.columns[0], axis=1)\n",
    "Y_train=df['class']\n",
    "X_train=df.iloc[:,:-1]\n",
    "Y_test=df1['class']\n",
    "X_test=df1.iloc[:,:-1]\n",
    "X_train=X_train.drop(X_train.columns[[6,12,17]],axis=1)\n",
    "X_test=X_test.drop(X_test.columns[[6,12,17]],axis=1)\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"feature importance level metrics is \",model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.5154021335251109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import scipy.stats as sps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import neighbors\n",
    "from scipy.stats import *\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=13)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc = clf.score(X_test,Y_test)\n",
    "print(\"accuracy is \",acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for decision tree is  58.25542370849814\n"
     ]
    }
   ],
   "source": [
    "#decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inlin\n",
    "from sklearn.metrics import accuracy_score\n",
    "li=[]\n",
    "#best split at 6500\n",
    "c = tree.DecisionTreeClassifier(min_samples_split =6500)\n",
    "features=list(X_train.columns.values)\n",
    "dt = c.fit(X_train, Y_train)\n",
    "Y_pred = c.predict(X_test)\n",
    "score = accuracy_score(Y_test, Y_pred) * 100\n",
    "print(\"accuracy for decision tree is \", score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "%matplotlib inline\n",
    "dot_data = tree.export_graphviz(dt, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         class_names= [\"14-16\",\"24-26\",\"34-36\",\"44-46\"],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fiamge.txt\", \"w\") as f:\n",
    "    f = tree.export_graphviz(c, out_file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  51.54320987654321\n",
      "51.54320987654321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred=0\n",
    "count=0\n",
    "for i in range(0,len(Y_test)):\n",
    "    if clf.predict([X_test.iloc[1]]) == Y_test[i] :\n",
    "        pred+=1\n",
    "print(\"accuracy is \", pred/len(X_test)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
